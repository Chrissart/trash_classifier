{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención de los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset de trashnet que es un conjunto de datos que tiene alrededor de 2500 imágenes de seis tipos diferentes de basura: vidrio, papel, cartón, plástico, metal y basura."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```consola\n",
    "git clone https://github.com/garythung/trashnet\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomprimir el zip con la data\n",
    "\n",
    "data_path: str = './trashnet/data'\n",
    "zip_path: str = './trashnet/data/dataset-resized.zip'\n",
    "zip_ref: zipfile.ZipFile = zipfile.ZipFile(zip_path, 'r')\n",
    "zip_ref.extractall(data_path)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos entre entrenamiento y validación\n",
    "validation_path: str = './data/valid'\n",
    "train_path: str = './data/train'\n",
    "\n",
    "if not os.path.exists(validation_path):\n",
    "    os.makedirs(validation_path)\n",
    "if not os.path.exists(train_path):\n",
    "    os.makedirs(train_path)\n",
    "\n",
    "unzipped_data_path = './trashnet/data/dataset-resized'\n",
    "\n",
    "for file in os.listdir(unzipped_data_path):\n",
    "    # Se crean los nuevos directorios para data de entrenamiento y validación\n",
    "    if file != '.DS_Store':\n",
    "        if not os.path.exists(os.path.join(train_path, file)):\n",
    "            os.makedirs(os.path.join(train_path, file))\n",
    "        if not os.path.exists(os.path.join(validation_path, file)):\n",
    "            os.makedirs(os.path.join(validation_path, file))\n",
    "\n",
    "for file in os.listdir(unzipped_data_path):\n",
    "    if file != '.DS_Store':\n",
    "        # Extrae el 20% de las imágenes para validación (siguiendo la \"regla\" de 80/20)\n",
    "        for subfile in os.listdir(os.path.join(unzipped_data_path, file)):\n",
    "            if subfile != '.DS_Store':\n",
    "                if np.random.rand(1) < 0.2:\n",
    "                    os.rename(os.path.join(unzipped_data_path, file, subfile), os.path.join(validation_path, file, subfile))\n",
    "                else:\n",
    "                    os.rename(os.path.join(unzipped_data_path, file, subfile), os.path.join(train_path, file, subfile))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que cada clase tenga la misma cantidad de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = \"./data/\"\n",
    "\n",
    "image_extension = \".jpg\"  # Change the extension if necessary\n",
    "\n",
    "train_subdirectories = [os.path.join(root_directory, \"train\", subdirectory) for subdirectory in os.listdir(os.path.join(root_directory, \"train\"))]\n",
    "valid_subdirectories = [os.path.join(root_directory, \"valid\", subdirectory) for subdirectory in os.listdir(os.path.join(root_directory, \"valid\"))]\n",
    "\n",
    "train_min_image_count = min([len([file for file in os.listdir(subdirectory) if file.endswith(image_extension)]) for subdirectory in train_subdirectories])\n",
    "valid_min_image_count = min([len([file for file in os.listdir(subdirectory) if file.endswith(image_extension)]) for subdirectory in valid_subdirectories])\n",
    "\n",
    "for subdirectory in train_subdirectories:\n",
    "    image_files = [file for file in os.listdir(subdirectory) if file.endswith(image_extension)]\n",
    "    image_count = len(image_files)\n",
    "    difference = image_count - train_min_image_count\n",
    "\n",
    "    for i in range(difference):\n",
    "        image_to_remove = image_files[i]\n",
    "        image_to_remove_path = os.path.join(subdirectory, image_to_remove)\n",
    "        os.remove(image_to_remove_path)\n",
    "\n",
    "    remaining_image_count = len([file for file in os.listdir(subdirectory) if file.endswith(image_extension)])\n",
    "    print(f\"Remaining image count in {subdirectory}: {remaining_image_count}\")\n",
    "\n",
    "for subdirectory in valid_subdirectories:\n",
    "    image_files = [file for file in os.listdir(subdirectory) if file.endswith(image_extension)]\n",
    "    image_count = len(image_files)\n",
    "    difference = image_count - valid_min_image_count\n",
    "\n",
    "    for i in range(difference):\n",
    "        image_to_remove = image_files[i]\n",
    "        image_to_remove_path = os.path.join(subdirectory, image_to_remove)\n",
    "        os.remove(image_to_remove_path)\n",
    "\n",
    "    remaining_image_count = len([file for file in os.listdir(subdirectory) if file.endswith(image_extension)])\n",
    "    print(f\"Remaining image count in {subdirectory}: {remaining_image_count}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras import regularizers\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los sets de entrenamiento y validación\n",
    "train_data_generator: ImageDataGenerator = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.4\n",
    ")\n",
    "    \n",
    "val_data_generator: ImageDataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Crea los generadores de data para entrenamiento y validación \n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=160,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True  # Se mezcla la data de entrenamiento\n",
    ")\n",
    "\n",
    "val_generator = val_data_generator.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=160,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False # No se mezcla la data de validación \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos algunas de las imagenes post-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtén un lote de imágenes y etiquetas del generador de entrenamiento\n",
    "images, labels = next(train_generator)\n",
    "\n",
    "# Define los nombres de las clases en el mismo orden que se utilizó al crear el generador\n",
    "class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "\n",
    "# Muestra las primeras 20 imágenes\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(class_names[labels[i].argmax()])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del modelo\t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el modelo base de ResNet101V2  y le hacemos un fine-tuning para que se adapte a nuestro problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base model using a pre-trained ResNet50V2 model\n",
    "# Create a base model using a pre-trained ResNet101V2 model\n",
    "base_model = tf.keras.applications.ResNet101V2(\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new layers on top of the base model\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# add another layer\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-ajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Pass the callback to the fit method\n",
    "pre_fine_tuning_history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last few layers of the base model\n",
    "for layer in base_model.layers[-20:]:  # Increase the number of layers to fine-tune\n",
    "    if not isinstance(layer, layers.BatchNormalization):  # Don't apply regularization to BatchNormalization layers\n",
    "        layer.kernel_regularizer = regularizers.l2(0.01)  # Add L2 regularization\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model (necessary after changing layer trainability)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),  # Experiment with the learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping callback\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Continue training the model with fine-tuning\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model/ResNet101V2_TrashClassifierV1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado del modelo\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el modelo desde el archivo\n",
    "model = load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, 'r', label='Precision de entrenamiento')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Precision de validacion')\n",
    "plt.title('Valor de la precision de entrenamiento y validacion')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(epochs, loss, 'r', label='Perdida de entrenamiento')\n",
    "plt.plot(epochs, val_loss, 'b', label='Perdida de validacion')\n",
    "plt.title('Perdida de entrenamiento y validacion')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels of the test images.\n",
    "test_labels = val_generator.classes\n",
    "\n",
    "# make a prediction\n",
    "predictions = model.predict(val_generator)\n",
    "\n",
    "# Get most likely class\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "errors = np.where(predicted_classes != test_labels)[0]\n",
    "print(\"Número de errores = {}/{}\".format(len(errors),val_generator.samples))\n",
    "accuracy = (val_generator.samples-len(errors))/val_generator.samples\n",
    "print(\"Precisión = \", accuracy*100, \"%\")\n",
    "\n",
    "cm = confusion_matrix(test_labels, predicted_classes)\n",
    "cm_plot_labels = ['cartón','vidrio','metal','papel','plastico','basura (miscelaneo)']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=cm_plot_labels, yticklabels=cm_plot_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_img = tf.keras.preprocessing.image.load_img\n",
    "\n",
    "# show some misclassified examples\n",
    "for iterator in range(len(errors)):\n",
    "    ax, fig = plt.subplots(1,1)\n",
    "    pred_class = np.argmax(predictions[errors[iterator]])\n",
    "    pred_label = cm_plot_labels[pred_class]\n",
    "\n",
    "    title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "        cm_plot_labels[test_labels[errors[iterator]]], pred_label, predictions[errors[iterator]][pred_class])\n",
    "\n",
    "    original = load_img('{}/{}'.format(validation_path, val_generator.filenames[errors[iterator]]))\n",
    "    plt.imshow(original)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    if iterator == 9:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Example usage:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m img_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./data/prueba_2.jpg\u001b[39m\u001b[39m'\u001b[39m  \n\u001b[1;32m----> 5\u001b[0m predicted_class \u001b[39m=\u001b[39m predict_image(model, img_path)\n\u001b[0;32m      6\u001b[0m predicted_class\n",
      "File \u001b[1;32md:\\documentos\\mac\\deepLearning_bigData\\trash_classifier\\src\\predict_image.py:10\u001b[0m, in \u001b[0;36mpredict_image\u001b[1;34m(model, image, img_size)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_image\u001b[39m(model, image, img_size\u001b[39m=\u001b[39m(\u001b[39m150\u001b[39m, \u001b[39m150\u001b[39m)):\n\u001b[0;32m      9\u001b[0m     \u001b[39m# Load the image\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     img \u001b[39m=\u001b[39m load_img(image\u001b[39m.\u001b[39;49mfile, target_size\u001b[39m=\u001b[39mimg_size)\n\u001b[0;32m     12\u001b[0m     \u001b[39m# Convert the image to a numpy array and scale the pixel values to the range [0,1]\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     img_array \u001b[39m=\u001b[39m img_to_array(img) \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'file'"
     ]
    }
   ],
   "source": [
    "from src.predict_image import predict_image\n",
    "\n",
    "# Example usage:\n",
    "img_path = './data/prueba_2.jpg'  \n",
    "predicted_class = predict_image(model, img_path)\n",
    "predicted_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trash_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
